{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f428c3-2bac-4d59-8f8a-01882985ba3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Root: /Users/iwamurairifuki/evolang2026/out/exp20251103_213554_gen50_m8_f7_alpha5\n",
      "\n",
      "--- Replicates: 0 ---\n",
      "\n",
      "--- Replicates: 1 ---\n",
      "\n",
      "--- Replicates: 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwamurairifuki/anaconda3/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Replicates: 3 ---\n",
      "\n",
      "--- Replicates: 4 ---\n",
      "\n",
      "--- Saving Final Results ---\n",
      "Generation data saved to individual 'rep_i/generations' folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations\n",
    "import datetime\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "# --- Agent クラス および 補助関数 (省略、変更なし) ---\n",
    "class Agent:\n",
    "    def __init__(self, bitN_meaning, bitN_form, m2s, s2m, i):\n",
    "        self.bitN_meaning = bitN_meaning\n",
    "        self.bitN_form = bitN_form\n",
    "        self.m2s = m2s\n",
    "        self.s2m = s2m\n",
    "        self.m2m = nn.Sequential(m2s, s2m)\n",
    "        self.num = i\n",
    "        \n",
    "def create_agent(bitN_meaning, bitN_form, nodeN, i):\n",
    "    m2s = nn.Sequential(\n",
    "        nn.Linear(bitN_meaning, nodeN), nn.Sigmoid(),\n",
    "        nn.Linear(nodeN, bitN_form), nn.Sigmoid()\n",
    "    )\n",
    "    s2m = nn.Sequential(\n",
    "        nn.Linear(bitN_form, nodeN), nn.Sigmoid(),\n",
    "        nn.Linear(nodeN, bitN_meaning), nn.Sigmoid()\n",
    "    )\n",
    "    return Agent(bitN_meaning, bitN_form, m2s, s2m, i)\n",
    "\n",
    "def int2bin(bitN, value):\n",
    "    return [int(x) for x in f\"{value:0{bitN}b}\"]\n",
    "\n",
    "def generate_structured_meaning_space(N_A, N_P, N_R, N_F=1):\n",
    "    bitN_meaning = N_A + N_P + N_R + N_F\n",
    "    all_meanings = []\n",
    "    meaning_pairs = []\n",
    "    predicates_tensors = [torch.tensor(int2bin(N_R, i), dtype=torch.float32) for i in range(2 ** N_R)]\n",
    "    agents_tensors = [torch.tensor(int2bin(N_A, i), dtype=torch.float32) for i in range(2 ** N_A)]\n",
    "    patients_tensors = [torch.tensor(int2bin(N_P, i), dtype=torch.float32) for i in range(2 ** N_P)]\n",
    "    foci = [torch.tensor([0.0], dtype=torch.float32), torch.tensor([1.0], dtype=torch.float32)]\n",
    "\n",
    "    for R in predicates_tensors:\n",
    "        for A in agents_tensors:\n",
    "            for P in patients_tensors:\n",
    "                situation_parts = [A, P, R]\n",
    "                M_act = torch.cat(situation_parts + [foci[0]])\n",
    "                M_pass = torch.cat(situation_parts + [foci[1]])\n",
    "                all_meanings.append(M_act)\n",
    "                all_meanings.append(M_pass)\n",
    "                meaning_pairs.append((M_act, M_pass))\n",
    "    return all_meanings, meaning_pairs\n",
    "\n",
    "def gen_supervised_data(tutor, all_meanings):\n",
    "    T = []\n",
    "    for meaning in all_meanings:\n",
    "        signal = tutor.m2s(meaning.unsqueeze(0)).detach().round().squeeze(0)\n",
    "        T.append((meaning.numpy(), signal.numpy()))\n",
    "    return T\n",
    "\n",
    "def gen_unsupervised_data(all_meanings, A_size):\n",
    "    U = []\n",
    "    for _ in range(A_size):\n",
    "        meaning = random.choice(all_meanings)\n",
    "        U.append(meaning.numpy())\n",
    "    return U\n",
    "\n",
    "def train_combined(agent, tutor, A_size, B_size, all_meanings, epochs, alpha=5.0):\n",
    "    optimiser_m2s = torch.optim.SGD(agent.m2s.parameters(), lr=5.0)\n",
    "    optimiser_s2m = torch.optim.SGD(agent.s2m.parameters(), lr=5.0)\n",
    "    optimiser_m2m = torch.optim.SGD(list(agent.m2s.parameters()) + list(agent.s2m.parameters()), lr=5.0)\n",
    "    loss_function = nn.MSELoss(reduction='none')\n",
    "    T = gen_supervised_data(tutor, all_meanings)\n",
    "    A = gen_unsupervised_data(all_meanings, A_size)\n",
    "    N_F = 1\n",
    "    N_SITUATION = agent.bitN_meaning - N_F\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        B1 = [random.choice(T) for _ in range(B_size)]\n",
    "        B2 = B1.copy()\n",
    "        random.shuffle(B2)\n",
    "\n",
    "        for i in range(B_size):\n",
    "            # M -> S\n",
    "            optimiser_m2s.zero_grad()\n",
    "            m2s_meaning, m2s_signal = B1[i]\n",
    "            m2s_meaning = torch.tensor(m2s_meaning, dtype=torch.float32).unsqueeze(0)\n",
    "            m2s_signal = torch.tensor(m2s_signal, dtype=torch.float32).unsqueeze(0)\n",
    "            pred_m2s = agent.m2s(m2s_meaning)\n",
    "            loss_m2s = loss_function(pred_m2s, m2s_signal).mean()\n",
    "            loss_m2s.backward()\n",
    "            optimiser_m2s.step()\n",
    "\n",
    "            # S -> M\n",
    "            optimiser_s2m.zero_grad()\n",
    "            s2m_meaning, s2m_signal = B2[i]\n",
    "            s2m_signal = torch.tensor(s2m_signal, dtype=torch.float32).unsqueeze(0)\n",
    "            s2m_meaning = torch.tensor(s2m_meaning, dtype=torch.float32).unsqueeze(0)\n",
    "            pred_s2m = agent.s2m(s2m_signal)\n",
    "            loss_s2m = loss_function(pred_s2m, s2m_meaning).mean()\n",
    "            loss_s2m.backward()\n",
    "            optimiser_s2m.step()\n",
    "\n",
    "            # Autoencoder (M -> S -> M)\n",
    "            meanings_u = [random.choice(A) for _ in range(20)]\n",
    "            for meaning in meanings_u:\n",
    "                optimiser_m2m.zero_grad()\n",
    "                auto_m = torch.tensor(meaning, dtype=torch.float32).unsqueeze(0)\n",
    "                pred_m2m = agent.m2m(auto_m)\n",
    "                \n",
    "                loss_elements = loss_function(pred_m2m, auto_m)\n",
    "                loss_situation = loss_elements[:, :N_SITUATION]\n",
    "                loss_focus = loss_elements[:, N_SITUATION:]\n",
    "                weighted_loss_focus = alpha * loss_focus\n",
    "                loss_auto = torch.cat((loss_situation, weighted_loss_focus), dim=1).mean()\n",
    "                \n",
    "                loss_auto.backward()\n",
    "                optimiser_m2m.step()\n",
    "                \n",
    "    return T\n",
    "                \n",
    "def iterated_learning(generations=20, N_A=2, N_P=2, N_R=2, N_F=1, bitN_form=5, nodeN=8, A_size=75, B_size=75, epochs=20, alpha=5.0):\n",
    "    \n",
    "    bitN_meaning = N_A + N_P + N_R + N_F\n",
    "    tutor = create_agent(bitN_meaning, bitN_form, nodeN, 1)\n",
    "\n",
    "    stability_scores = []\n",
    "    expressivity_scores = []\n",
    "    compositionality_scores = []\n",
    "    alternation_scores = []\n",
    "    topsim_scores = [] # ★ TopSim スコアのリスト\n",
    "    posdis_scores = []\n",
    "    \n",
    "    all_meanings, meaning_pairs = generate_structured_meaning_space(N_A, N_P, N_R, N_F)\n",
    "    \n",
    "    all_meaning_signal_pairs = []\n",
    "\n",
    "    for gen in range(1, generations + 1):\n",
    "        pupil = create_agent(bitN_meaning, bitN_form, nodeN, gen)\n",
    "        current_T = train_combined(pupil, tutor, A_size, B_size, all_meanings, epochs, alpha=alpha)\n",
    "        all_meaning_signal_pairs.append(current_T)\n",
    "\n",
    "        stability_scores.append(stability(tutor, pupil, all_meanings))\n",
    "        expressivity_scores.append(expressivity(pupil, all_meanings))\n",
    "        compositionality_scores.append(compositionality(pupil, all_meanings))\n",
    "        alternation_scores.append(alternation(pupil, all_meanings, meaning_pairs))\n",
    "        topsim_scores.append(TopSim(pupil, all_meanings)) # ★ TopSim スコアを計算・追加\n",
    "        posdis_scores.append(PosDis(pupil, all_meanings))\n",
    "\n",
    "        tutor = pupil\n",
    "\n",
    "    return (np.array(stability_scores), \n",
    "            np.array(expressivity_scores), \n",
    "            np.array(compositionality_scores), \n",
    "            np.array(alternation_scores), \n",
    "            np.array(topsim_scores), \n",
    "            np.array(posdis_scores), \n",
    "            all_meaning_signal_pairs)\n",
    "\n",
    "# --- スコア計算関数 (省略、変更なし) ---\n",
    "def stability(tutor, pupil, all_meanings):\n",
    "    tutor.m2s.eval()\n",
    "    pupil.s2m.eval()\n",
    "    matches = 0\n",
    "    total_meanings = len(all_meanings)\n",
    "    with torch.no_grad():\n",
    "        for meaning in all_meanings:\n",
    "            m = meaning.clone().detach().float().unsqueeze(0)\n",
    "            tutor_m2s_sig = tutor.m2s(m)\n",
    "            pupil.s2m.eval()\n",
    "            pupil_s2m_mn = pupil.s2m(tutor_m2s_sig)\n",
    "            original_arr = meaning.numpy() > 0.5\n",
    "            decoded_arr = pupil_s2m_mn.squeeze(0).numpy() > 0.5\n",
    "            if np.array_equal(original_arr, decoded_arr):\n",
    "                matches += 1\n",
    "    return matches / total_meanings\n",
    "\n",
    "def expressivity(agent, all_meanings):\n",
    "    agent.m2s.eval()\n",
    "    unique_signals = set()\n",
    "    with torch.no_grad():\n",
    "        for meaning in all_meanings:\n",
    "            signal = tuple(agent.m2s(meaning).round().squeeze(0).numpy().astype(int))\n",
    "            unique_signals.add(signal)\n",
    "    return len(unique_signals) / (2 ** agent.bitN_form)\n",
    "\n",
    "def calculate_entropy(p):\n",
    "    if p <= 0 or p >= 1:\n",
    "        return 0.0\n",
    "    return -p * np.log2(p) - (1 - p) * np.log2(1 - p)\n",
    "\n",
    "def compositionality(agent, all_meanings):\n",
    "    agent.m2s.eval()\n",
    "    n_m = agent.bitN_meaning\n",
    "    n_f = agent.bitN_form\n",
    "    num_messages = len(all_meanings)\n",
    "    meaning_matrix = np.zeros((n_m, num_messages), dtype=int)\n",
    "    signal_matrix = np.zeros((n_f, num_messages), dtype=int)\n",
    "\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for m in all_meanings:\n",
    "            s = agent.m2s(m.unsqueeze(0)).detach().round().squeeze(0)\n",
    "            meaning_matrix[:, cnt] = m.numpy()\n",
    "            signal_matrix[:, cnt] = s.numpy()\n",
    "            cnt += 1\n",
    "\n",
    "    fact_min_entropies = np.zeros(n_m)\n",
    "    fact_best_word = np.zeros(n_m, dtype=int)\n",
    "\n",
    "    for i in range(n_m):\n",
    "        min_entropy = np.inf\n",
    "        best_j = -1\n",
    "        for j in range(n_f):\n",
    "            p = np.sum(meaning_matrix[i, :] * signal_matrix[j, :]) / (num_messages / 2)\n",
    "            h_ij = calculate_entropy(p)\n",
    "\n",
    "            if h_ij < min_entropy:\n",
    "                min_entropy = h_ij\n",
    "                best_j = j\n",
    "        fact_min_entropies[i] = min_entropy\n",
    "        fact_best_word[i] = best_j\n",
    "\n",
    "    adjusted_entropies = fact_min_entropies.copy()\n",
    "    for j in range(n_f):\n",
    "        facts_using_j = np.where(fact_best_word == j)[0]\n",
    "        if len(facts_using_j) > 1:\n",
    "            best_fact = facts_using_j[np.argmin(fact_min_entropies[facts_using_j])]\n",
    "\n",
    "            for idx in facts_using_j:\n",
    "                if idx != best_fact:\n",
    "                    adjusted_entropies[idx] = 1.0\n",
    "\n",
    "    average_adjusted_entropy = np.mean(adjusted_entropies)\n",
    "    return 1 - average_adjusted_entropy\n",
    "\n",
    "def alternation(agent, all_meanings, meaning_pairs):\n",
    "    agent.m2s.eval()\n",
    "    matches = 0\n",
    "    total_pairs = len(meaning_pairs)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for M_act, M_pass in meaning_pairs:\n",
    "            S_act = agent.m2s(M_act.unsqueeze(0)).round().squeeze(0).numpy().astype(int)\n",
    "            S_pass = agent.m2s(M_pass.unsqueeze(0)).round().squeeze(0).numpy().astype(int)\n",
    "            \n",
    "            if not np.array_equal(S_act, S_pass):\n",
    "                matches += 1\n",
    "                \n",
    "    return matches / total_pairs\n",
    "\n",
    "\n",
    "def count_meaning_distance_ability(v1, v2):\n",
    "    distance = np.sum(v1 != v2)\n",
    "    return distance\n",
    "\n",
    "def count_meaning_distance_process(meaning_vectors):\n",
    "    meaning_distance_list = []\n",
    "    pairs = combinations(meaning_vectors, 2)\n",
    "    for v1, v2 in pairs:\n",
    "        distance = count_meaning_distance_ability(v1, v2)\n",
    "        meaning_distance_list.append(distance)\n",
    "    return meaning_distance_list\n",
    "\n",
    "def count_form_distance_ability(v1, v2):\n",
    "    count = np.sum(v1 != v2)\n",
    "    return count\n",
    "\n",
    "def count_form_distance_process(form_vectors):\n",
    "    form_distance_list = []\n",
    "    pairs = combinations(form_vectors, 2)\n",
    "    for v1, v2 in pairs:\n",
    "        distance = count_form_distance_ability(v1, v2)\n",
    "        form_distance_list.append(distance)\n",
    "    return form_distance_list\n",
    "\n",
    "# ★★★ TopSim 関数 ★★★\n",
    "def TopSim(agent, all_meanings):\n",
    "    agent.m2s.eval()\n",
    "    meaning_vectors = []\n",
    "    form_vectors = []\n",
    "    \n",
    "    with torch.no_grad(): # 勾配計算を停止\n",
    "        for meaning_tensor in all_meanings:\n",
    "            meaning_array = meaning_tensor.numpy()\n",
    "            meaning_vectors.append(meaning_array)\n",
    "            \n",
    "            signal_tensor = agent.m2s(meaning_tensor.unsqueeze(0)).round().squeeze(0)\n",
    "            form_array = signal_tensor.numpy()\n",
    "            form_vectors.append(form_array)\n",
    "    \n",
    "    if len(meaning_vectors) < 2:\n",
    "        return np.nan\n",
    "        \n",
    "    meaning_distance_list = count_meaning_distance_process(meaning_vectors)\n",
    "    form_distance_list = count_form_distance_process(form_vectors)\n",
    "    \n",
    "    if len(meaning_vectors) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    TopSim_value, TopSim_p_value = pearsonr(meaning_distance_list, form_distance_list)\n",
    "    \n",
    "    # 構成性スコアとして絶対値を返す (通常、TopSimの相関係数は正の値が構成的と解釈される)\n",
    "    return TopSim_value\n",
    "\n",
    "### posdis\n",
    "def calculate_probabilities(data_vector):\n",
    "    counts = Counter(data_vector)\n",
    "    total = len(data_vector)\n",
    "\n",
    "    return {val: count / total for val, count in counts.items()}\n",
    "\n",
    "def calculate_joint_probabilities(var1, var2): # 同時確率P(X, Y)\n",
    "    joint_counts = Counter(zip(var1, var2))\n",
    "    total = len(var1)\n",
    "\n",
    "    return {pair: count / total for pair, count in joint_counts.items()}\n",
    "\n",
    "def H(data_vector): # エントロピー計算 (log2を使用)\n",
    "    probabilities = list(calculate_probabilities(data_vector).values())\n",
    "    \n",
    "    return entropy(probabilities, base=2)\n",
    "\n",
    "def I(var1, var2): # 相互情報量 # I(X; Y) = H(X) + H(Y) - H(X, Y)\n",
    "    joint_probabilities = list(calculate_joint_probabilities(var1, var2).values())\n",
    "    H_joint = entropy(joint_probabilities, base=2)\n",
    "    \n",
    "    return H(var1) + H(var2) - H_joint\n",
    "\n",
    "\n",
    "\n",
    "# def PosDis(agent, all_meanings):\n",
    "    \n",
    "#     agent.m2s.eval()\n",
    "#     meaning_vectors = []\n",
    "#     form_vectors = []\n",
    "    \n",
    "#     with torch.no_grad(): # 勾配計算を停止\n",
    "#         for meaning_tensor in all_meanings:\n",
    "#             meaning_array = meaning_tensor.numpy()\n",
    "#             meaning_vectors.append(meaning_array)\n",
    "            \n",
    "#             signal_tensor = agent.m2s(meaning_tensor.unsqueeze(0)).round().squeeze(0)\n",
    "#             form_array = signal_tensor.numpy()\n",
    "#             form_vectors.append(form_array)\n",
    "    \n",
    "\n",
    "#     N, MESSAGE_LEN = form_vectors.shape\n",
    "#     _, ATTRIBUTES_DIM = meaning_vectors.shape\n",
    "    \n",
    "#     posdis_scores = []\n",
    "    \n",
    "#     for j in range(MESSAGE_LEN): # 各メッセージ_jのエントロピー\n",
    "#         s_j = all_messages[:, j]\n",
    "#         H_s_j = H(s_j)\n",
    "#         if H_s_j == 0:\n",
    "#             continue\n",
    "            \n",
    "#         I_scores = []\n",
    "#         for i in range(ATTRIBUTES_DIM): # 各属性_iのエントロピー\n",
    "#             a_i = all_attributes[:, i]\n",
    "            \n",
    "#             I_s_j_a_i = I(s_j, a_i) # メッセージ_j と 属性_i の相互情報量\n",
    "#             I_scores.append((I_s_j_a_i, i))\n",
    "            \n",
    "#         # 3. a_j1 と a_j2 を決定し、情報ギャップを計算\n",
    "#         if not I_scores:\n",
    "#             continue\n",
    "            \n",
    "#         I_scores.sort(key=lambda x: x[0], reverse=True)  # 相互情報量の降順でソート\n",
    "        \n",
    "#         I_aj1 = I_scores[0][0] # 最大の情報量\n",
    "#         I_aj2 = I_scores[1][0] # 2番目に大きい\n",
    "#         information_gap = I_aj1 - I_aj2 # I(s_j; a_j1) - I(s_j; a_j2) の情報ギャップ\n",
    "        \n",
    "#         # posdis の項を計算し、リストに追加\n",
    "#         posdis_term = information_gap / H_s_j\n",
    "#         posdis_scores.append(posdis_term)\n",
    "\n",
    "#     # 5. すべての項の平均を最終スコアとする\n",
    "#     if not posdis_scores:\n",
    "#         return 0.0 # 有効な位置がない場合\n",
    "    \n",
    "#     PosDis_value = np.mean(posdis_scores)\n",
    "        \n",
    "#     return PosDis_value\n",
    "\n",
    "# ... (TopSim関数群と補助関数は省略) ...\n",
    "\n",
    "def PosDis(agent, all_meanings):\n",
    "    \n",
    "    agent.m2s.eval()\n",
    "    meaning_vectors_list = [] # 一時的なリスト名に変更\n",
    "    form_vectors_list = []    # 一時的なリスト名に変更\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for meaning_tensor in all_meanings:\n",
    "            meaning_array = meaning_tensor.numpy()\n",
    "            meaning_vectors_list.append(meaning_array)\n",
    "            \n",
    "            signal_tensor = agent.m2s(meaning_tensor.unsqueeze(0)).round().squeeze(0)\n",
    "            form_array = signal_tensor.numpy()\n",
    "            form_vectors_list.append(form_array)\n",
    "    \n",
    "    # ★★★ 修正箇所：リストを一つのNumPy行列にスタック ★★★\n",
    "    all_messages = np.stack(form_vectors_list, axis=0)      # 形式行列 (N x M_LEN)\n",
    "    all_attributes = np.stack(meaning_vectors_list, axis=0) # 意味行列 (N x ATT_DIM)\n",
    "\n",
    "    N, MESSAGE_LEN = all_messages.shape\n",
    "    _, ATTRIBUTES_DIM = all_attributes.shape\n",
    "    \n",
    "    posdis_scores = []\n",
    "    \n",
    "    # 修正: ループ内で all_messages, all_attributes を使用\n",
    "    \n",
    "    for j in range(MESSAGE_LEN): # 各メッセージビット j\n",
    "        s_j = all_messages[:, j] # j列目 (形式ビット j の値リスト)\n",
    "        H_s_j = H(s_j)\n",
    "        if H_s_j == 0:\n",
    "            continue\n",
    "            \n",
    "        I_scores = []\n",
    "        for i in range(ATTRIBUTES_DIM): # 各属性ビット i\n",
    "            a_i = all_attributes[:, i] # i列目 (意味ビット i の値リスト)\n",
    "            \n",
    "            I_s_j_a_i = I(s_j, a_i) # メッセージ j と 属性 i の相互情報量\n",
    "            I_scores.append((I_s_j_a_i, i))\n",
    "            \n",
    "        # 3. a_j1 と a_j2 を決定し、情報ギャップを計算\n",
    "        if not I_scores or len(I_scores) < 2:\n",
    "            continue\n",
    "            \n",
    "        I_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        I_aj1 = I_scores[0][0]\n",
    "        I_aj2 = I_scores[1][0]\n",
    "        information_gap = I_aj1 - I_aj2\n",
    "        \n",
    "        posdis_term = information_gap / H_s_j\n",
    "        posdis_scores.append(posdis_term)\n",
    "\n",
    "    if not posdis_scores:\n",
    "        return 0.0\n",
    "        \n",
    "    PosDis_value = np.mean(posdis_scores)\n",
    "        \n",
    "    return PosDis_value\n",
    "\n",
    "\n",
    "\n",
    "# --- ★ 修正・新設: 個別試行の結果をプロットする関数 (rep_i/figures/ に格納) ---\n",
    "def plot_individual_results(score_array, score_name, generations, save_path):\n",
    "    # rep_i/figures には、その試行の結果のみを格納する (単独線)\n",
    "    gens = np.arange(1, generations + 1)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "    color = {'stability': 'purple', 'expressivity': 'blue', 'compositionality': 'orange', 'alternation': 'red', 'topsim': 'green', 'posdis': 'grey'}.get(score_name, 'black')\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # 単独の試行結果のみをプロット\n",
    "    plt.plot(gens, score_array, color=color, linewidth=3)\n",
    "    \n",
    "    plt.xlabel(\"Generations\", fontsize=13)\n",
    "    plt.ylabel(score_name, fontsize=14)\n",
    "    plt.ylim(0.00, 1.00) \n",
    "\n",
    "    if save_path is not None:\n",
    "        # ファイル名は平均と分けるため、そのまま (repフォルダ内なのでユニーク)\n",
    "        file_path = os.path.join(save_path, f\"{score_name}.png\")\n",
    "        plt.savefig(file_path, dpi=300)\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# --- ★ 修正: 平均結果をプロットする関数 (average_figures/ に格納) ---\n",
    "def plot_average_results(all_scores_by_rep, score_name, generations, save_path):\n",
    "    # average_figures には、全ての個別線と平均線を重ねたグラフを格納する\n",
    "    gens = np.arange(1, generations + 1)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    color = {'stability': 'purple', 'expressivity': 'blue', 'compositionality': 'orange', 'alternation': 'red', 'topsim': 'green', 'posdis': 'grey'}.get(score_name, 'black')\n",
    "\n",
    "    # 全試行のスコアをNumpy配列にスタックし、平均を計算\n",
    "    stacked_scores = np.stack(all_scores_by_rep, axis=0)\n",
    "    mean_scores = np.mean(stacked_scores, axis=0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    # 1. 全ての個別線をプロット（薄い線）\n",
    "    for i in range(stacked_scores.shape[0]):\n",
    "        plt.plot(gens, stacked_scores[i], color=color, alpha=0.2, linewidth=1.5)\n",
    "        \n",
    "    # 2. 平均線をプロット（太い線）\n",
    "    plt.plot(gens, mean_scores, color=color, linewidth=4, label='Average')\n",
    "    \n",
    "    plt.xlabel(\"Generations\", fontsize=13)\n",
    "    plt.ylabel(f\"Average {score_name}\", fontsize=14)\n",
    "    plt.ylim(0.00, 1.00) \n",
    "\n",
    "    if save_path is not None:\n",
    "        # ファイル名は Average を示す\n",
    "        file_path = os.path.join(save_path, f\"{score_name}_average.png\")\n",
    "        plt.savefig(file_path, dpi=300)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Jupyter Notebookで表示するために一度だけplt.show()を呼ぶ\n",
    "    # Note: 4つの平均グラフが表示される\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- ★ save_data_txt 関数を修正 (rep_i/generations/ に保存) ---\n",
    "def save_data_txt(all_meaning_signal_pairs_by_rep, experiment_root):\n",
    "    \n",
    "    for rep_i, gen_data in enumerate(all_meaning_signal_pairs_by_rep):\n",
    "        \n",
    "        # 保存パス: rep_i/generations/\n",
    "        data_save_dir = os.path.join(experiment_root, f\"rep_{rep_i}\", \"generations\")\n",
    "        os.makedirs(data_save_dir, exist_ok=True)\n",
    "        \n",
    "        for gen_i, T in enumerate(gen_data):\n",
    "            filename = f\"data_rep_{rep_i}_gen_{gen_i+1}.txt\"\n",
    "            filepath = os.path.join(data_save_dir, filename)\n",
    "            \n",
    "            with open(filepath, 'w') as f:\n",
    "                if T:\n",
    "                    len_M = len(T[0][0])\n",
    "                    len_S = len(T[0][1])\n",
    "                    header = f\"# Meaning bits: {len_M}, Signal bits: {len_S}\\n\"\n",
    "                    header += \"# Format: [M_0 M_1 ... M_{N_M-1}] -> [S_0 S_1 ... S_{N_S-1}]\\n\"\n",
    "                    f.write(header)\n",
    "                \n",
    "                for meaning_array, signal_array in T:\n",
    "                    meaning_str = ' '.join(map(str, meaning_array.astype(int)))\n",
    "                    signal_str = ' '.join(map(str, signal_array.astype(int)))\n",
    "                    f.write(f\"{meaning_str} -> {signal_str}\\n\")\n",
    "    print(f\"Generation data saved to individual 'rep_i/generations' folders.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    generations = 50\n",
    "    replicates = 5 \n",
    "\n",
    "    all_stability_scores = []\n",
    "    all_expressivity_scores = []\n",
    "    all_compositionality_scores = []\n",
    "    all_alternation_scores = []\n",
    "    all_topsim_scores = []\n",
    "    all_posdis_scores = []\n",
    "    all_meaning_signal_pairs_by_rep = [] \n",
    "    \n",
    "    N_A, N_P, N_R, N_F, bitN_form = 3, 2, 2, 1, 7\n",
    "    # N_A, N_P, N_R, N_F, bitN_form = 3, 2, 2, 1, 8\n",
    "    alpha = 5.0\n",
    "    \n",
    "    # --- パスとフォルダ名の動的生成 (Jupyter環境対応) ---\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    bitN_meaning = N_A + N_P + N_R + N_F\n",
    "    setting_name = f\"gen{generations}_m{bitN_meaning}_f{bitN_form}_alpha{int(alpha)}\"\n",
    "    experiment_dir_name = f\"exp{timestamp}_{setting_name}\"\n",
    "\n",
    "    current_cwd = os.getcwd() \n",
    "    evolang2026_dir = os.path.dirname(current_cwd)\n",
    "    \n",
    "    experiment_root = os.path.join(evolang2026_dir, \"out\", experiment_dir_name)\n",
    "    \n",
    "    print(f\"Experiment Root: {experiment_root}\")\n",
    "    \n",
    "    score_names = ['stability', 'expressivity', 'compositionality', 'alternation', 'topsim', 'posdis']\n",
    "    \n",
    "    # --- ★ シミュレーションとデータ収集 (ループ内) ---\n",
    "    for i in range(replicates):\n",
    "        print(f\"\\n--- Replicates: {i} ---\")\n",
    "        \n",
    "        stability, expressivity, compositionality, alternation, topsim, posdis, all_meaning_signal_pairs = iterated_learning(\n",
    "            generations=generations, N_A=N_A, N_P=N_P, N_R=N_R, N_F=N_F, bitN_form=bitN_form, alpha=alpha)\n",
    "            \n",
    "        # 1. スコアとデータ配列を全体リストに追加\n",
    "        all_stability_scores.append(stability)\n",
    "        all_expressivity_scores.append(expressivity)\n",
    "        all_compositionality_scores.append(compositionality)\n",
    "        all_alternation_scores.append(alternation)\n",
    "        all_topsim_scores.append(topsim)\n",
    "        all_posdis_scores.append(posdis)\n",
    "        all_meaning_signal_pairs_by_rep.append(all_meaning_signal_pairs)\n",
    "\n",
    "        # 2. 個別プロットを rep_i/figures/ に保存 (単独線)\n",
    "        rep_folder = os.path.join(experiment_root, f\"rep_{i}\")\n",
    "        individual_figures_path = os.path.join(rep_folder, \"figures\")\n",
    "        \n",
    "        # スコアをリストではなく、個別のNumpy配列として渡す\n",
    "        scores = [stability, expressivity, compositionality, alternation, topsim, posdis]\n",
    "        for score_array, name in zip(scores, score_names):\n",
    "            plot_individual_results(score_array, name, generations, individual_figures_path)\n",
    "\n",
    "\n",
    "    # --- ★ ループ終了後、平均プロットとデータ保存を実行 ---\n",
    "    \n",
    "    print(\"\\n--- Saving Final Results ---\")\n",
    "    \n",
    "    # 1. 平均プロットを average_figures/ に保存 (個別線と平均線を重ねる)\n",
    "    average_figures_path = os.path.join(experiment_root, \"average_figures\")\n",
    "    all_scores = [all_stability_scores, all_expressivity_scores, all_compositionality_scores, all_alternation_scores, all_topsim_scores, all_posdis_scores]\n",
    "    \n",
    "    for scores, name in zip(all_scores, score_names):\n",
    "        plot_average_results(scores, name, generations, average_figures_path)\n",
    "\n",
    "    # 2. 意味-形式ペアのTXT保存 (rep_i/generations/ に保存)\n",
    "    save_data_txt(all_meaning_signal_pairs_by_rep, experiment_root)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
